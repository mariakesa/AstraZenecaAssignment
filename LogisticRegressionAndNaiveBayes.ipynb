{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_df=pd.read_csv('25100_dat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transform(tot_df):\n",
    "    corpus_meds=tot_df['meds_str'].values\n",
    "    corpus_reacts=tot_df['reacts_str'].values\n",
    "    \n",
    "    c_med = CountVectorizer()\n",
    "    med_feats = c_med.fit_transform(corpus_meds).toarray()\n",
    "    \n",
    "    c_r=CountVectorizer()\n",
    "    reacts_feats=c_r.fit_transform(corpus_reacts).toarray()\n",
    "    \n",
    "    feats=np.concatenate([med_feats,reacts_feats],axis=1)\n",
    "    \n",
    "    return feats,c_med.vocabulary_, c_r.vocabulary_\n",
    "    \n",
    "feats,med_vocab,reacts_vocab=feature_transform(tot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       death\n",
      "0        0.0\n",
      "1        1.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        0.0\n",
      "...      ...\n",
      "25095    0.0\n",
      "25096    0.0\n",
      "25097    0.0\n",
      "25098    0.0\n",
      "25099    0.0\n",
      "\n",
      "[25100 rows x 1 columns]\n",
      "(2162, 1)\n"
     ]
    }
   ],
   "source": [
    "targets=tot_df[['death']].fillna(0)\n",
    "print(targets)\n",
    "np.mean(targets)\n",
    "print(targets[targets.death==1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = targets[targets.death==0]\n",
    "df_minority = targets[targets.death==1]\n",
    " \n",
    "#downsample\n",
    "downsampled = resample(df_majority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=2162,    # to match majority class\n",
    "                                 random_state=123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       death\n",
      "21779    0.0\n",
      "17071    0.0\n",
      "19281    0.0\n",
      "23595    0.0\n",
      "16713    0.0\n",
      "...      ...\n",
      "5936     0.0\n",
      "7182     0.0\n",
      "20052    0.0\n",
      "18979    0.0\n",
      "11709    0.0\n",
      "\n",
      "[2162 rows x 1 columns]\n",
      "Int64Index([21779, 17071, 19281, 23595, 16713,  8326, 14528, 24302,   100,\n",
      "            24751,\n",
      "            ...\n",
      "            19620, 21122,  5357, 22892,  6362,  5936,  7182, 20052, 18979,\n",
      "            11709],\n",
      "           dtype='int64', length=2162)\n",
      "Int64Index([    1,    16,    19,    37,   209,   231,   244,   262,   269,\n",
      "              272,\n",
      "            ...\n",
      "            24988, 24995, 25002, 25009, 25014, 25015, 25020, 25035, 25053,\n",
      "            25074],\n",
      "           dtype='int64', length=2162)\n"
     ]
    }
   ],
   "source": [
    "print(downsampled[downsampled.death==0])\n",
    "downsampled_inds=downsampled[downsampled.death==0].index\n",
    "death_inds=df_minority.index\n",
    "print(downsampled_inds)\n",
    "print(death_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_no_death=feats[downsampled_inds,:]\n",
    "feats_death=feats[death_inds,:]\n",
    "feats=np.concatenate([feats_no_death,feats_death],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4324, 1)\n"
     ]
    }
   ],
   "source": [
    "targets=np.concatenate([downsampled.values,df_minority.values],axis=0)\n",
    "print(targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feats,targets,test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:  0.9580995275138602\n"
     ]
    }
   ],
   "source": [
    "pcs=PCA(n_components=1000)\n",
    "X_train_pcs=pcs.fit_transform(X_train)\n",
    "X_test_pcs=pcs.transform(X_test)\n",
    "print('Explained variance: ',pcs.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train_pcs, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8913805185704274"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=clf.predict(X_test_pcs)\n",
    "accuracy_score(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[621, 100],\n",
       "       [ 55, 651]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred,labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5654740622286485"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf=MultinomialNB().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8794674141555712"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=clf.predict(X_test)\n",
    "accuracy_score(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[664,  57],\n",
       "       [115, 591]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred,labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(med_vocab)\n",
    "#print(reacts_vocab)\n",
    "\n",
    "tot_vocab={}\n",
    "for j in med_vocab.keys():\n",
    "    tot_vocab[med_vocab[j]]=j\n",
    "for i in reacts_vocab.keys():\n",
    "    tot_vocab[reacts_vocab[i]+len(med_vocab.keys())]=i\n",
    "#print(tot_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 11094)\n",
      "11094\n",
      "[ -8.16844592  -6.68036887  -6.53083713  -5.97122135  -7.62944942\n",
      "  -6.81851921  -7.06983364  -4.54220204  -5.49923556  -7.34176735\n",
      "  -5.8516762   -6.89548025  -7.28114273  -4.72986101  -5.53964509\n",
      "  -6.02001151  -5.34367145  -6.97886186  -9.42120889  -6.37668645\n",
      "  -6.81851921  -7.34176735  -6.85625953  -7.9171315   -7.9171315\n",
      "  -5.77055065  -8.03491453  -7.9171315   -7.40630587  -6.33016644\n",
      "  -6.93630224  -8.3225966   -6.35315596  -6.02001151  -8.72806171\n",
      "  -6.00348221  -5.98722169  -6.78215156  -7.9171315   -5.90966345\n",
      "  -7.22398432  -6.12537203  -6.28571468  -8.50491816  -7.9171315\n",
      "  -7.7164608   -7.22398432  -8.03491453  -6.89548025  -5.23155415\n",
      "  -8.3225966   -6.22253577  -8.72806171  -8.72806171  -8.03491453\n",
      "  -8.3225966   -8.50491816  -7.1186238   -8.03491453  -6.53083713\n",
      "  -6.71315869  -6.30769358  -6.42547662  -9.42120889  -6.45079443\n",
      "  -6.42547662  -6.02001151  -9.01574378  -7.06983364  -9.01574378\n",
      "  -5.69551547  -6.74706024  -7.7164608   -9.42120889  -9.01574378\n",
      "  -5.82389663  -6.68036887  -7.7164608   -7.47529874  -6.58799555\n",
      "  -9.42120889  -6.85625953  -6.97886186  -6.55900801  -6.93630224\n",
      "  -6.71315869  -8.03491453  -6.93630224  -8.16844592  -7.9171315\n",
      "  -6.97886186  -9.01574378  -8.72806171  -8.16844592  -8.72806171\n",
      "  -7.02331362  -7.7164608   -9.42120889  -6.97886186 -10.11435607]\n",
      "death\n",
      "failure\n",
      "disease\n",
      "haemorrhage\n",
      "cardiac\n",
      "respiratory\n",
      "pulmonary\n",
      "drug\n",
      "decreased\n",
      "acute\n",
      "calcium\n",
      "pneumonia\n",
      "progression\n",
      "pain\n",
      "disorder\n",
      "infection\n",
      "increased\n",
      "to\n",
      "arrest\n",
      "dianeal\n",
      "malignant\n",
      "neoplasm\n",
      "renal\n",
      "infarction\n",
      "myocardial\n",
      "blood\n",
      "revlimid\n",
      "xeloda\n",
      "hepatic\n",
      "low\n",
      "cell\n",
      "sepsis\n",
      "oedema\n",
      "dyspnoea\n",
      "chronic\n",
      "aspirin\n",
      "abdominal\n",
      "gastrointestinal\n",
      "lung\n",
      "of\n",
      "cancer\n",
      "sodium\n",
      "acid\n",
      "shock\n",
      "toxicity\n",
      "dexamethasone\n",
      "acetaminophen\n",
      "carcinoma\n",
      "syndrome\n",
      "letairis\n",
      "graft\n",
      "hydrochloride\n",
      "versus\n",
      "host\n",
      "various\n",
      "cerebral\n",
      "tracleer\n",
      "overdose\n",
      "agents\n",
      "erbitux\n",
      "injury\n",
      "use\n",
      "label\n",
      "glivec\n",
      "unknown\n",
      "off\n",
      "vitamin\n",
      "rituximab\n",
      "plavix\n",
      "suicide\n",
      "ineffective\n",
      "anaemia\n",
      "physical\n",
      "holoxan\n",
      "erlotinib\n",
      "fatigue\n",
      "omeprazole\n",
      "furosemide\n",
      "oxycodone\n",
      "peripheral\n",
      "cyclophosphamide\n",
      "metoprolol\n",
      "hypotension\n",
      "metformin\n",
      "multiple\n",
      "asthenia\n",
      "prednisolone\n",
      "xarelto\n",
      "health\n",
      "general\n",
      "sulfate\n",
      "with\n",
      "tablet\n",
      "deterioration\n",
      "metastases\n",
      "prednisone\n",
      "fentanyl\n",
      "organ\n",
      "hypertension\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "print(clf.feature_log_prob_.shape)\n",
    "print(len(tot_vocab.keys()))\n",
    "probs=clf.feature_log_prob_\n",
    "top_death_class=probs[1,:].argsort()[-100:][::-1]\n",
    "print(probs[0,top_death_class])\n",
    "for j in top_death_class:\n",
    "    print(tot_vocab[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression k-fold accuracies: [0.8706697459584296, 0.8960739030023095, 0.8937644341801386, 0.9076212471131639, 0.8935185185185185, 0.9027777777777778, 0.9027777777777778, 0.8888888888888888, 0.9097222222222222, 0.9097222222222222]\n",
      "Naive Bayes k-fold accuracies: [0.8429561200923787, 0.8568129330254042, 0.8683602771362586, 0.8637413394919169, 0.8842592592592593, 0.8773148148148148, 0.8680555555555556, 0.8773148148148148, 0.8657407407407407, 0.8726851851851852]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "acc_lst_lr=[]\n",
    "acc_lst_nb=[]\n",
    "for train_index, test_index in kf.split(feats):\n",
    "    \n",
    "    X_train, X_test = feats[train_index], feats[test_index]\n",
    "    y_train, y_test = targets[train_index].reshape(-1,), targets[test_index].reshape(-1,)\n",
    "    pcs=PCA(n_components=1000)\n",
    "    X_train_pcs=pcs.fit_transform(X_train)\n",
    "    X_test_pcs=pcs.transform(X_test)\n",
    "    clf = LogisticRegression(random_state=0).fit(X_train_pcs, y_train)\n",
    "    pred=clf.predict(X_test_pcs)\n",
    "    acc_lst_lr.append(accuracy_score(pred,y_test))\n",
    "    clf=MultinomialNB().fit(X_train,y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    acc_lst_nb.append(accuracy_score(pred,y_test))\n",
    "\n",
    "print('Logistic regression k-fold accuracies:', acc_lst_lr)\n",
    "print('Naive Bayes k-fold accuracies:', acc_lst_nb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy 95% confidence interval: 0.8890140110708556 0.906093336461434\n",
      "Naive Bayes accuracy 95% confidence interval: 0.8593455233160673 0.8761026847071983\n"
     ]
    }
   ],
   "source": [
    "print('Logistic regression accuracy 95% confidence interval:', np.mean(acc_lst_lr)-2.262*(np.std(acc_lst_lr,ddof=1)/np.sqrt(10)),np.mean(acc_lst_lr)+2.262*(np.std(acc_lst_lr,ddof=1)/np.sqrt(10)))\n",
    "print('Naive Bayes accuracy 95% confidence interval:', np.mean(acc_lst_nb)-2.262*(np.std(acc_lst_nb,ddof=1)/np.sqrt(10)),np.mean(acc_lst_nb)+2.262*(np.std(acc_lst_nb,ddof=1)/np.sqrt(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following t-test for testing between the differences of two mean accuracies is not valid. The samples are not independent in k-fold cross-validation. The following procedure is know to lead to a lot of Type I errors (incorrectly rejecting the null). However, we can the p-value as an approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3751506029290326e-05 2.3751506029263742e-05\n"
     ]
    }
   ],
   "source": [
    "#Statistical test to determine whether there is a significant difference in classification accuracies for logistic\n",
    "#regression and naive bayes\n",
    "#Calculated according to a blog post https://towardsdatascience.com/inferential-statistics-series-t-test-using-numpy-2718f8f9bf2f\n",
    "var_lr = np.array(acc_lst_lr).var(ddof=1)\n",
    "var_nb = np.array(acc_lst_nb).var(ddof=1)\n",
    "#std deviation\n",
    "s = np.sqrt((var_lr + var_nb)/2)\n",
    "## Calculate the t-statistics\n",
    "N=10\n",
    "t = (np.array(acc_lst_lr).mean() - np.array(acc_lst_nb).mean())/(s*np.sqrt(2/N))\n",
    "\n",
    "## Compare with the critical t-value\n",
    "#Degrees of freedom\n",
    "df = 2*N - 2\n",
    "\n",
    "#p-value after comparison with the t \n",
    "p = 2*(1 - stats.t.cdf(t,df=df))\n",
    "\n",
    "t2, p2 = stats.ttest_ind(np.array(acc_lst_lr),np.array(acc_lst_nb))\n",
    "print(p,p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value of the t-test between classification accuracies 2.3751506029290326e-05\n"
     ]
    }
   ],
   "source": [
    "print('P-value of the t-test between classification accuracies', p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
